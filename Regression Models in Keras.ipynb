{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f3e0e9-1af2-4c7c-91c3-b5708cbe0122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# Keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    " \n",
    "# Sci-kit learn\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set pandas as the default output for sklearn\n",
    "from sklearn import set_config\n",
    "set_config(transform_output='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b7c846-0a12-4bf9-996a-f823b0bf351e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function for plotting each metric\n",
    "def plot_history(history, figsize=(6,12), marker='o'):\n",
    "       \n",
    "    # Get list of metrics from history\n",
    "    metrics = [c for c in history.history if not c.startswith('val_')]\n",
    "    \n",
    "    ## Separate row for each metric\n",
    "    fig, axes = plt.subplots(nrows=len(metrics),figsize=figsize)\n",
    "    \n",
    "    # For each metric\n",
    "    for i, metric_name in enumerate(metrics):\n",
    "    \n",
    "        # Get the axis for the current metric\n",
    "        ax = axes[i]\n",
    "    \n",
    "        # Get metric from history.history\n",
    "        metric_values = history.history[metric_name]\n",
    "        # Get epochs from history\n",
    "        epochs = history.epoch\n",
    "    \n",
    "        # Plot the training metric\n",
    "        ax.plot(epochs, metric_values, label=metric_name, marker=marker)\n",
    "    \n",
    "        ## Check if val_{metric} exists. if so, plot:\n",
    "        val_metric_name = f\"val_{metric_name}\"\n",
    "        if val_metric_name in history.history:\n",
    "            # Get validation values and plot\n",
    "            metric_values = history.history[val_metric_name]\n",
    "            ax.plot(epochs,metric_values,label=val_metric_name, marker=marker)\n",
    "    \n",
    "        # Final subplot adjustments \n",
    "        ax.legend()\n",
    "        ax.set_title(metric_name)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e36ee2-7a4f-408b-871c-bc10dbfba711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    " \n",
    "reg_url = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vTg36jLawSOgGP9hp0oJ3OYZiHMWbuGLiau-8DMjtcKNv7v9Zy_zFBQs9gZU-44GGeIyfXE2iwo26_z/pub?output=csv'\n",
    "df_reg = pd.read_csv(reg_url)\n",
    " \n",
    "# drop car name columns\n",
    "df_reg = df_reg.drop(columns='car name')\n",
    " \n",
    "df_reg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2928a1d1-b5ba-4898-8da8-63594ba0247e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing values and duplicates\n",
    "print('missing values', df_reg.info())\n",
    "print('\\nduplicated rows', df_reg.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4f5394-9cbe-49bb-b484-61c74199cfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    " \n",
    "X = df_reg.drop(columns='mpg')\n",
    "y = df_reg['mpg']\n",
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a65adbb-26d9-4572-a253-904d1f168042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists of columns for transformer\n",
    "cat_cols = ['cylinders','model year','origin']\n",
    "num_cols = X_train.columns.drop(cat_cols)\n",
    "\n",
    "# PREPROCESSING PIPELINE FOR NUMERIC DATA\n",
    "\n",
    "# instantiate preprocessors\n",
    "scaler = StandardScaler()\n",
    "# Make a numeric preprocessing pipeline\n",
    "num_pipe = make_pipeline(scaler)\n",
    "# Making a numeric tuple for ColumnTransformer\n",
    "num_tuple = ('numeric', num_pipe, num_cols)\n",
    "\n",
    "\n",
    "# PREPROCESSING PIPELINE FOR ONE-HOT-ENCODED DATA\n",
    "\n",
    "# Instantiate the individual preprocessors\n",
    "ohe_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "# Make pipeline with imputer and encoder\n",
    "ohe_pipe = make_pipeline(ohe_encoder)\n",
    "# Making a ohe_tuple for ColumnTransformer\n",
    "ohe_tuple = ('categorical', ohe_pipe, cat_cols)\n",
    "\n",
    "# Instantiate with verbose_feature_names_out=False\n",
    "col_transformer = ColumnTransformer([num_tuple, ohe_tuple],\n",
    "                                    verbose_feature_names_out=False)\n",
    "# Fit on training data\n",
    "col_transformer.fit(X_train)\n",
    "\n",
    "# Transform the training data\n",
    "X_train_tf = col_transformer.transform(X_train)\n",
    "# Transform the testing data\n",
    "X_test_tf = col_transformer.transform(X_test)\n",
    "# View the processed training data\n",
    "X_train_tf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364d08b8-3f74-46d5-9682-fabf849ac16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define shape\n",
    "input_shape = X_train_tf.shape[1]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da6bf99-4484-4053-b178-076c3ec5ef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build regression model within function\n",
    "def build_model():\n",
    "    # Instantiate Model \n",
    "    model = Sequential()\n",
    "    \n",
    "    # First hidden layer\n",
    "    model.add(Dense(10, # How many neurons you have in your first hidden layer\n",
    "                input_dim =input_shape, # What is the shape of your input features (number of columns)\n",
    "                activation = 'relu')) # What activation function are you using?\n",
    "    model.add(Dense(10, \n",
    "                activation = 'relu'))\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(Dense(1, activation = 'linear'))\n",
    "    \n",
    "    # Compile Model\n",
    "    model.compile(loss = 'mse', optimizer = 'adam',\n",
    "             metrics=[metrics.MeanAbsoluteError(), metrics.RootMeanSquaredError()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f9bf77-ebb3-43cc-9a56-33bc100534ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call our build function to build model\n",
    "reg_model = build_model()\n",
    "\n",
    "# Get model summary\n",
    "reg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2828514-de5f-409a-8828-5c69479af0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760c3bd9-d77c-4f78-9d74-e78fee5b9729",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = reg_model.fit(X_train_tf, y_train,\n",
    "                        validation_split = .2,\n",
    "                        epochs=100,\n",
    "                        verbose=0, callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a072459e-b96f-478d-bab9-8b794721dcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot learning \n",
    "plot_history(history);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9c3d93-5f9e-45d1-a94b-c65cc0c9bf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    " \n",
    "y_pred = reg_model.predict(X_test_tf)\n",
    " \n",
    "print(f'final RMSE: {np.sqrt(mean_squared_error(y_test, y_pred))}')\n",
    "print(f'final MAE: {mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'final R2: {r2_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675c2b3b-2bfe-42de-90d6-3701d418bdea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
